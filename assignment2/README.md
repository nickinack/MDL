# MDL Project on Genetic Algorithms

Abhishekh Sivakumar

Karthik Viswanathan

Team 66

## Summary

In this project, we tried to unwind the effects caused by overfitting. This was done so by searching for optimal solutions by searching for parameters which could balance the training and validation errors and simultaneously reduce them. This was done by using Genetic Algorithms. The main concept behind genetic algorithms is to create an ecosystem of healthy individuals by the theory of natural selection. We start with a randomly initialised population which has noise added to the overfit vector. We evolve this population for n generations, where n iteration during which the population has sufficiently converged. The following steps were followed:

### Initialize population

The initial population was generated by mutating the overfit vectors by adding noise. In order to add noise, we had to create an individual which has been perturbed by a certain distribution. We tried out various forms of distributions, but we could find our best vectors by using uniform and gaussian distribution. The initial population was created as follows:

```python
overfit = [0.0, -1.45799022e-12, -2.28980078e-13,  4.62010753e-11, 
					-1.75214813e-10, -1.83669770e-15,  8.52944060e-16,  2.29423303e-05,
					 -2.04721003e-06, -1.59792834e-08,  9.98214034e-10]
for i in range(pop_cnt):
        for j in range(gene_size):
            if not debug:
                population[i] = [x + x*distribution for x in overfit]
                if population[i][j] == 0:
                    population[i][j] = population[i][j] + np.random.uniform(-1e-23, 1e-23)
```

The distributions used are as follows:

```python
# Uniform Distribution
distribution = np.random.uniform(-0.04, 0.04)
# Gaussian Distribution
distribution = np.random.normal(1,0.03)
```

Once the initial population was created, we tried to use selection, mutation and crossover algorithms in order to replicate the process of natural selection. A brief code snippet has been provided below in order to summarise the genetic algorithm:

```python
generations = 30
curr_generation = 0
while curr_generation < generations:
	# Run selection
	ma = selection(params)
	pa = selection(params)
	# Run crossover
	for i in range(n_matings):
            ma_el, pa_el = population[ma[i], :], population[pa[i], :]  # choose the two parents from the ma, pa indices
            c1, c2 = crossover(ma_el, pa_el, crossover_strategy)  # Produce two offsprings from the selected parent
            population[-j-1,:] = c1 # Replace the unfit population with the new children
            population[-j-2,:] = c2
            j = j + 2
# Run mutation
population = mutate_population(population)
```

The details of the selection, crossover and the mutation algorithms have been explained below:

### Selection

In order to prevent the genetic algorithm from converging into a local minima, we ran selection algorithms. If we selected the top k individuals out of the n individuals and decided to crossover, we observed that this reaches a local minima. Hence, we decided to use three different selection algorithms: stochastic universal sampling, roulette wheel and classical linear rank. All of these gave us similar results, but classical linear rank edged over the other selection algorithms and hence, we decided to include it in our final submission.

```python
if strat == "classic_linear_rank":
        rank = np.zeros(len(population))
        sorted_ind = np.argsort(population)
        for i in range(0 , len(sorted_ind)):
            rank[sorted_ind[i]] = i
        parent_ind = selection(rank , "rowlette_wheel" , N)
```

The above piece of code ranks the k individuals in terms of their fitness values. Once this is done, it creates a roulette wheel which is rotated in order to select which individual becomes a parent. The code snippet for selection using roulette wheel has been provided below:

```python
if strat == "rowlette_wheel":
        min_element = min(population)
        tot_fitness = 0
        selection_prob = []
        for i in range(0 , len(population)):
            population[i] = population[i] + abs(min_element)
        for i in range(0 , len(population)):
            tot_fitness = tot_fitness + population[i]
        for i in range(0 , len(population)):
            selection_prob.append(population[i]/tot_fitness)
        for i in range(0 , N):
            parent_ind.append(np.random.choice(len(population) , p=selection_prob))
```

It is very much possible that the fittest individuals can produce multiple children and weaker individuals have a very less chance of becoming parents;  just like in the real-life scenario. The probability that the same individuals are selected as parents also exist (asexual reproduction); and even if this was the case, the crossover and the mutation functions make sure that the individuals mate in order to produce genes different from their parents. While same parents can cause premature convergence, our crossover function ensures demestic grouping which ensures that children compete among themselves.

### Crossover

The crossover function we have used is known as simulated binary crossover. The main intention of using the simulated binary crossover was to create individuals which average out near the parent's genes; but have the individual's gene values far away from that of their parents. Each point of the chromosome has the same
probability to be selected as a crossover point. This means, we could induce more mutation into the parent without getting concerned about the fitnesses of their children. The code snippet for SBX crossover has been provided below:

```python
if str == "simulated_binary":
        u = random.random()
        n_c = 3

        if u < 0.6:
            beta = (2 * u)**((n_c + 1)**-1)
        else:
            beta = ((2*(1-u))**-1)**((n_c + 1)**-1)
        offspring1 = 0.5*((1 + beta) * np.array(parent1) + (1 - beta) * np.array(parent2))
        offspring2 = 0.5*((1 - beta) * np.array(parent1) + (1 + beta) * np.array(parent2))
```

Over here, `beta` is the spread factor and `n_c`  is the distribution index. We wanted to induce mutations; but not perturb the individuals such that these mutations were too much. Hence, we chose the value of `n_c`  to be 3. The following graph depicts the position of offspring solutions relative to the position of their parents.

![MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled.png](MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled.png)

`beta` is calculated using the probability density function that simulates the single point crossover. It is calculated as follows:

![MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%201.png](MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%201.png)

By convention,

$$\frac{child1 + child2}{2} = \frac{parent1 + parent2}{2}$$

### Mutation

The mutation function we used aims at adding noise to the genes of an individual. The mutation occurs for an individual with some probability `n_mutations` every generation. We fine tuned `n_mutations` every generation such that individuals in the earlier generations are subject to more mutations compared to their children and grand children. After a certain generation, the `n_mutations` becomes constant. This is to ensure that mutations exist, but are performed at a minimal rate. The code snippet of mutation has been provided below:

```python
if str == "mutation_2":
        for i in range(0 , len(individual)):
            u = np.random.randint(0 , 10)
            if u < 3:
                delta = np.random.uniform(0.94 , 1.06)
                individual[i] = individual[i]*delta
```

Mutation is performed on an individual by adding small noise corresponding to the range of the overfit vector (`[-0.06,0.06]` in this case) to a gene chosen randomly (uniform distribution) in an individual.

### Fitness function

The selection of parents is done using the fitness function. The goal of the GA is to converge the fitness function at high value. We tried various fitness functions, but the fitness function below gave us good results. 

$$ratio = n*e_{train} + m*e_{val} + o*|e_{train}-e_{val}|
$$

$$fitness = \frac{1}{ratio}$$

The `fitness` is inversely related to the `ratio` . `n` and `m` are used to quantify the rate at which we want to reduce our train error and val error. `o` has been used in order to provide weightage to the similarity of train and val errors. The more similar and less the errors are, the better our coefficients generated are performing on the train and val dataset. During different runs, we played around with the values of `n`, `m` and `o` depending on our expectations and learnings from the previous run. 

### Hyperparameters

1. `pop_cnt` : The population count per generation. This was usually in the range of 10-13 depending on the number of API calls we had left. We decided to go for a lower population size as this gave us more iterations and hence more scope for the GA to converge.
2. `gene_size`: The number of genes in an individual. As we have 11 coefficients, the gene size was set to a constant (11).
3. `max_gen` : The number of generations the GA is performed during one run. This was usually in the in the range of 10-80 depending on the number of API calls we had left.
4. `n_matings` : The number of matings which occurred during a generation. The value of this was set to `(pop_cnt - 3) // 2` to ensure that every individual did not become a parent and this number made sure that the selection algorithms played a vital role in deciding who the parents were. 
5. `n_mutation` : The probability with which an individual in a generation is selected in order to perform mutation on it. Initially, we set `n_mutation` to be high and we used the concept of simulated annealing in order to reduce the mutations as the number of generations progressed. This was to ensure we did not perturb individuals which were already fit. The initial value of `n_mutation` was `0.7` and the least value was `0.3`.
6. `sure`: Every generation, we selected the fittest member of the population and passed it on into the next generation irrespective of replacements. This was to ensure that our best error values for a generation did not exceed the errors of the previous generation.

### Miscellaneous

In order to minimize the errors, we used the results from previous runs as the initial population for some runs. These previous runs had instances where the coefficients were stuck in a local minima. By doing a fresh run, we ensured that the mutations would give these coefficients enough push from the local minima in order to start descending again.

Before attempting the actual problem, we developed an overfitted model of our own and tested the correctness of our genetic algorithms with it. This was to ensure that our model was working properly and our fitnesses were increasing as the generations progressed.

## Heuristics

1. Use a weighted fitness function and vary the weights on different runs. We initially tried to vary the fitness function mid-way, but this did not make sense as we could not visualise the direction of our genetic algorithm. Hence, we decided to use the best coefficients from the previous run and vary the fitness function in a fresh run.
2. Simulated Annealing. We reduced the mutation probability as the number of generations increased.
3. We used Simulated Binary crossover over a continuous space. We fine tuned the distribution index and the spread factors in order to reach a minimal error.
4. Instead of initializing the population from the overfit vectors, we achieved better results on the unseen dataset by producing the initial population from a random subset of the overfit vector's genes along with considerable noise. Applying this heuristic required that we have a significantly large population size so as to make use of the large random noise factor.

The mutation strategy that accompanied the above involved mutating the vector by setting a random subset of its genes with those of the overfit vectors along with some noise.

```python
overfit = [0.0, -1.45799022e-12, -2.28980078e-13,  4.62010753e-11, 
	   -1.75214813e-10, -1.83669770e-15,  8.52944060e-16,  2.29423303e-05,
	   -2.04721003e-06, -1.59792834e-08,  9.98214034e-10]
for i in range(pop_cnt):
        for j in range(gene_size):
		if np.random.uniform(0,1) < 0.3:
			population[i][j] = overfit[j] * np.random.uniform(0.5, 1.5)
```

### Statistics

We were able to achieve train and val errors as low as `7.2e10`. Our GA took almost `120` iterations in order to converge to this value. The population size was `12`. The fitness graph for one of the runs which gave us the best value has been shown below:

![MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%202.png](MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%202.png)

The error function for the same has shown below. The train errors can be seen fluctuating as we added an extra constraint which required for the train and val error to be in the same range. The train weight we assigned for this run was `0.2` and which also attributes to the heavy fluctuations in the train errors:

![MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%203.png](MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%203.png)

We fear that our best model might be overfitting on the train and validation dataset. Hence, we have also included some vectors which perform well on the test dataset (gave us good ranks) as a part of our submission.

## Iteration Diagrams

The coefficient diagram for some individual halfway during a random run has been shown below:

![MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%204.png](MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%204.png)

**Generation 'n:**

![MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%205.png](MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%205.png)

                                                                                            ||

                                                                                            ||                     (After Selection Gen n)

![MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%206.png](MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%206.png)

                                                                                            ||

                                                                                            ||                    (After crossover Gen n)

![MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%207.png](MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%207.png)

                                                                                            ||

                                                                                            ||                    (After Mutation and sorting Gen n)

![MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%208.png](MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%208.png)

                                                                                           ||                

                                                                                           ||                     (After Selection Gen n+1)

![MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%209.png](MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%209.png)

                                                                                          ||

                                                                                          ||                       (After Crossover Gen n+1)

![MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%2010.png](MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%2010.png)

                                                                                          ||

                                                                                          ||                     (After Mutation and sorting Gen n+1)

![MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%2011.png](MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%2011.png)

                                                                                          ||

                                                                                          ||                       (After selection Gen n+2)

![MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%2012.png](MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%2012.png)

                                                                                         ||

                                                                                         ||                       (After Crossover Gen n+2)

![MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%2013.png](MDL%20Project%20on%20Genetic%20Algorithms%2077c5c7d06cb542d09c64683afcd1eb33/Untitled%2013.png)

                                                                                                                  (After mutation Gen n+2)

### Outputs

The outputs and the generations corresponding to each outputs have been attached along with this report as a part of the submission.
